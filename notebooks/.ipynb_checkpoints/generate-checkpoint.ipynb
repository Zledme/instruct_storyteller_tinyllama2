{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a22d95-f400-4551-98eb-ab250f50d567",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c302e1ee-7d05-444e-b334-86c8b405d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "from model import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d6a96-0889-43fe-be11-3afd59d5449f",
   "metadata": {},
   "source": [
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924dcb86-c936-46cf-918b-7957b16c0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = '../tokenizer.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fabfdf6-048d-4221-9927-bfd1b78cca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '../models/lora_story_teller_110M.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "118e362d-1d46-4a87-b5f8-1ad5c1553e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7928409-e8f5-41dd-9c8f-852ec09c28d0",
   "metadata": {},
   "source": [
    "# load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3827ecdf-86f2-48d6-8002-9bf92d91f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SentencePieceProcessor(model_file=tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a822d5a-883f-4726-be85-20855cd3dfb3",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78bed1c6-e4d8-4bc4-83bb-0ccec422113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_prefix_from_state_dict(state_dict, unwanted_prefix):\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4f91c7-8d8b-4ebc-8d3f-c4aa484dbf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path, device, unwanted_prefix='_orig_mod'):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    config = checkpoint['model_args'] if isinstance(checkpoint['model_args'], ModelArgs) else ModelArgs(**checkpoint['model_args'])\n",
    "    model = Transformer(config)\n",
    "    if checkpoint.get('lora_finetune'):\n",
    "        apply_lora(\n",
    "            model, \n",
    "            targets=checkpoint['lora_targets'],\n",
    "            rank=checkpoint['lora_rank'],\n",
    "            dropout=checkpoint['lora_dropout'],\n",
    "            alpha=checkpoint['lora_alpha']\n",
    "        )\n",
    "    print(f\"Number of parameters: {sum([p.nelement() for p in model.parameters()])}\")\n",
    "    state_dict = checkpoint['model']\n",
    "    state_dict = remove_unwanted_prefix_from_state_dict(state_dict=state_dict, unwanted_prefix=unwanted_prefix)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f400d5d-4a58-4705-89ec-9dabd52fe42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 109824768\n"
     ]
    }
   ],
   "source": [
    "instruct_model, ckpt = load_model(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    device=device,\n",
    "    unwanted_prefix='',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd2625-7ed8-4a32-9811-5b3698022a2d",
   "metadata": {},
   "source": [
    "# sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdca52-da6b-4360-a606-a5bc2a249e9c",
   "metadata": {},
   "source": [
    "### generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85552534-8b1f-473d-a142-2783bd611a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraph(\n",
    "    model, \n",
    "    prompt,\n",
    "    max_new_tokens=400,\n",
    "    temperature=0.1,\n",
    "    top_k=10\n",
    "):\n",
    "    tokenized_prompt = [tokenizer.bos_id()] + tokenizer.encode(prompt)\n",
    "    tokenized_prompt = (torch.tensor(tokenized_prompt, dtype=torch.long, device=device)[None, ...])\n",
    "\n",
    "    paragraph = []\n",
    "    context_tokens = tokenized_prompt\n",
    "    for _ in range(max_new_tokens):\n",
    "        context_tokens = context_tokens[:, -min(model.params.max_seq_len, context_tokens.size(1)):]\n",
    "        output = model(context_tokens)\n",
    "        logits = output[:, -1, :]\n",
    "        logits = logits / temperature\n",
    "        v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "        logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        context_tokens = torch.cat((context_tokens, next_token), dim=1)\n",
    "        paragraph.append(next_token.item())\n",
    "        if next_token.item() == tokenizer.eos_id() or tokenizer.decode(paragraph[-3:]) == 'The end.':\n",
    "            break\n",
    "    return context_tokens, paragraph, tokenizer.decode(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72a79b5e-c663-43f6-8bea-e96515a7e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Write a story. In the story, try to use the verb \"climb\", the noun \"ring\" and the adjective \"messy\". Possible story:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4302b686-2b5e-4440-a96b-c8e29b80aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lily. She liked to climb trees. One day, she found a shiny ring on the ground. It was so pretty! She put it on her finger and ran around the park, happy as can be.\n",
      "But then, Lily noticed her hands were dirty from playing in the mud. She didn't want to get the ring dirty too. So, she went to the water fountain and washed her hands. The water was clean and made her hands shiny again.\n",
      "Lily felt proud of herself for finding the ring and was glad she wasn't too messy. She climbed back up the tree to show her friends the pretty ring on her finger. They all thought it was beautiful and wanted to climb the same tree to get a shiny ring from Lily. From that day on, they climbed trees together and always had fun, even if it meant getting a little dirty. The end.\n"
     ]
    }
   ],
   "source": [
    "_, tokens, paragraph = generate_paragraph(\n",
    "    model=instruct_model, \n",
    "    prompt=prompt,\n",
    "    max_new_tokens=400,\n",
    "    temperature=0.5,\n",
    "    top_k=10\n",
    ")\n",
    "print(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d27c3a-cfdf-4d9b-a476-98cb19aa0a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llama2karpathy]",
   "language": "python",
   "name": "conda-env-llama2karpathy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
