{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41a22d95-f400-4551-98eb-ab250f50d567",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec688b85-9358-4f34-a59f-1ee158666694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "from model import *\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d6a96-0889-43fe-be11-3afd59d5449f",
   "metadata": {},
   "source": [
    "# paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924dcb86-c936-46cf-918b-7957b16c0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = './tokenizer.model'\n",
    "# this is the same tokenizer as found in llama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fabfdf6-048d-4221-9927-bfd1b78cca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = './out/batch128.pt'\n",
    "checkpoint_path = './instruct_out/ckpt.pt'\n",
    "checkpoint_path = './instruct_out/ckpt.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118e362d-1d46-4a87-b5f8-1ad5c1553e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7928409-e8f5-41dd-9c8f-852ec09c28d0",
   "metadata": {},
   "source": [
    "# load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3827ecdf-86f2-48d6-8002-9bf92d91f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = SentencePieceProcessor(model_file=tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a822d5a-883f-4726-be85-20855cd3dfb3",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4f91c7-8d8b-4ebc-8d3f-c4aa484dbf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path, device, unwanted_prefix='_orig_mod', add_lora=False):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    if isinstance(checkpoint['model_args'], ModelArgs):\n",
    "        config = checkpoint['model_args']\n",
    "    else:\n",
    "        config = ModelArgs(**checkpoint['model_args'])\n",
    "    model = Transformer(config)\n",
    "    if add_lora:\n",
    "        lora_rank = 2\n",
    "        lora_dropout = 0.1\n",
    "        lora_alpha = 1.0\n",
    "        lora_targets = ['wk', 'wq', 'wo', 'wv']\n",
    "        apply_lora(\n",
    "            model, \n",
    "            targets=lora_targets,\n",
    "            rank=lora_rank,\n",
    "            dropout=lora_dropout,\n",
    "            alpha=lora_alpha\n",
    "        )\n",
    "    print(f\"Number of parameters: {sum([p.nelement() for p in model.parameters()])}\")\n",
    "    state_dict = checkpoint['model']\n",
    "    for k,v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    return model, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f400d5d-4a58-4705-89ec-9dabd52fe42b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add lora to layers.0.attention.wq\n",
      "add lora to layers.0.attention.wk\n",
      "add lora to layers.0.attention.wv\n",
      "add lora to layers.0.attention.wo\n",
      "add lora to layers.1.attention.wq\n",
      "add lora to layers.1.attention.wk\n",
      "add lora to layers.1.attention.wv\n",
      "add lora to layers.1.attention.wo\n",
      "add lora to layers.2.attention.wq\n",
      "add lora to layers.2.attention.wk\n",
      "add lora to layers.2.attention.wv\n",
      "add lora to layers.2.attention.wo\n",
      "add lora to layers.3.attention.wq\n",
      "add lora to layers.3.attention.wk\n",
      "add lora to layers.3.attention.wv\n",
      "add lora to layers.3.attention.wo\n",
      "add lora to layers.4.attention.wq\n",
      "add lora to layers.4.attention.wk\n",
      "add lora to layers.4.attention.wv\n",
      "add lora to layers.4.attention.wo\n",
      "add lora to layers.5.attention.wq\n",
      "add lora to layers.5.attention.wk\n",
      "add lora to layers.5.attention.wv\n",
      "add lora to layers.5.attention.wo\n",
      "add lora to layers.6.attention.wq\n",
      "add lora to layers.6.attention.wk\n",
      "add lora to layers.6.attention.wv\n",
      "add lora to layers.6.attention.wo\n",
      "add lora to layers.7.attention.wq\n",
      "add lora to layers.7.attention.wk\n",
      "add lora to layers.7.attention.wv\n",
      "add lora to layers.7.attention.wo\n",
      "add lora to layers.8.attention.wq\n",
      "add lora to layers.8.attention.wk\n",
      "add lora to layers.8.attention.wv\n",
      "add lora to layers.8.attention.wo\n",
      "add lora to layers.9.attention.wq\n",
      "add lora to layers.9.attention.wk\n",
      "add lora to layers.9.attention.wv\n",
      "add lora to layers.9.attention.wo\n",
      "add lora to layers.10.attention.wq\n",
      "add lora to layers.10.attention.wk\n",
      "add lora to layers.10.attention.wv\n",
      "add lora to layers.10.attention.wo\n",
      "add lora to layers.11.attention.wq\n",
      "add lora to layers.11.attention.wk\n",
      "add lora to layers.11.attention.wv\n",
      "add lora to layers.11.attention.wo\n",
      "Number of parameters: 109824768\n"
     ]
    }
   ],
   "source": [
    "instruct_model, ckpt = load_model(\n",
    "    checkpoint_path='./fine_tuning_instruct/ckpt.pt',\n",
    "    device=device,\n",
    "    unwanted_prefix='',\n",
    "    add_lora=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd2625-7ed8-4a32-9811-5b3698022a2d",
   "metadata": {},
   "source": [
    "# sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bdca52-da6b-4360-a606-a5bc2a249e9c",
   "metadata": {},
   "source": [
    "### generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "469fbdc6-1e25-44f5-a208-058a61733900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_new_tokens = 400 # number of tokens generated in each sample\n",
    "temperature = 0.3 # 1.0 = no change, < 1.0 = less random, > 1.0 = more random, in predictions\n",
    "top_k = 10 # retain only the top_k most likely tokens, clamp others to have 0 probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85552534-8b1f-473d-a142-2783bd611a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraph(model, prompt):\n",
    "    tokenized_prompt = [tokenizer.bos_id()] + tokenizer.encode(prompt)# bos=True, eos=False)\n",
    "    tokenized_prompt = (torch.tensor(tokenized_prompt, dtype=torch.long, device=device)[None, ...])\n",
    "    #paragraph = tokenized_prompt.flatten().tolist()\n",
    "\n",
    "    paragraph = []\n",
    "    context_tokens = tokenized_prompt\n",
    "    for _ in range(max_new_tokens):\n",
    "        context_tokens = context_tokens[:, -min(model.params.max_seq_len, context_tokens.size(1)):]\n",
    "        output = model(context_tokens)\n",
    "        \n",
    "        logits = output[:, -1, :]\n",
    "        \n",
    "        temp_scaled_logits = logits / temperature\n",
    "        v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "        logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_token = torch.multinomial(probs, num_samples=1)\n",
    "        context_tokens = torch.cat((context_tokens, next_token), dim=1)\n",
    "        #print(, type(next_token))\n",
    "        #paragraph.extend(next_token.flatten().tolist())\n",
    "        paragraph.append(next_token.item())\n",
    "        if next_token.item() == tokenizer.eos_id():\n",
    "            print('\\n eos \\n')\n",
    "            break\n",
    "        if tokenizer.decode(paragraph[-3:]) == 'The end.':\n",
    "            print('\\n The end \\n')\n",
    "            break\n",
    "    return context_tokens, paragraph, tokenizer.decode(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72a79b5e-c663-43f6-8bea-e96515a7e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Write a short story (3-5 paragraphs) which only uses very simple words that a 3 year old child would understand. In the story, try to at some point use the verb \"hope\", the noun \"search\" and the adjective \"comfortable\". Remember to only use simple words!\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4ffcda7-8453-464e-8966-10e67ffd2cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once writing the story, the child asked their mommy for help. Their mommy said she would be happy to help and she took a pen and paper. She showed the little one how to make words with their hands. The child was so excited to learn!\n",
      "They practiced writing their own words and soon enough they had made a whole story. They showed it to their mommy and she was so proud of them. The story had a lot of new words that the child loved to learn. Everyone was so happy!\n",
      "The story ended and the child was very proud of their accomplishment. They were so glad that they had tried to write a story. And now that the story was finished, they could go to bed and have sweet dreams. Once upon a time, in a small town, there was a little girl named Lily. Lily lived in a comfortable little house made of wood. She loved to play outside with her friends and explore the woods near her house.\n",
      "One sunny day, Lily and her friends were playing hide and seek. Lily found a dark cave and decided to hide inside. As she hid, she began to shiver because it was very cold. Suddenly, she heard a voice. \"Why are you shivering, little girl?\" the voice asked.\n",
      "Lily looked around and saw a big, friendly bear. \"I'm cold and scared,\" she said. The bear smiled and said, \"Don't be scared. Come with me, and I will show you a warm place where you can rest and be comfortable.\" Lily followed the bear, and they found a cozy cave. Lily thanked the bear and stayed there until she felt warm and comfortable again. She learned that making new friends can be scary, but they can also help you when you least expect it. And from that day on, Lily and the bear became the best of friends.\n"
     ]
    }
   ],
   "source": [
    "_, tokens, paragraph = generate_paragraph(instruct_model, prompt)\n",
    "print(paragraph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llama2karpathy]",
   "language": "python",
   "name": "conda-env-llama2karpathy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
